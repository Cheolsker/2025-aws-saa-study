1. 한 회사가 300개가 넘는 글로벌 웹사이트와 애플리케이션을 호스팅합니다. 이 회사는 매일 30TB가 넘는 클릭스트림 데이터를 분석할 플랫폼이 필요합니다.

솔루션 아키텍트는 클릭스트림 데이터를 전송하고 처리하기 위해 무엇을 해야 합니까?

A. AWS 데이터 파이프라인을 설계하여 데이터를 Amazon S3 버킷에 보관하고 해당 데이터로 Amazon EMR 클러스터를 실행하여 분석을 생성합니다.
B. Amazon EC2 인스턴스의 자동 확장 그룹을 생성하여 데이터를 처리하고 이를 Amazon Redshift에서 분석에 사용할 수 있도록 Amazon S3 데이터 레이크로 전송합니다.
C. Amazon CloudFront에 데이터를 캐시합니다. Amazon S3 버킷에 데이터를 저장합니다. S3 버킷에 객체가 추가되면 AWS Lambda 함수를 실행하여 분석을 위해 데이터를 처리합니다.
D. Amazon Kinesis Data Streams에서 데이터를 수집합니다. Amazon Kinesis Data Firehose를 사용하여 데이터를 Amazon S3 데이터 레이크로 전송합니다. 분석을 위해 Amazon Redshift에 데이터를 로드합니다.

2. 한 회사가 AWS에서 온라인 마켓플레이스 웹 애플리케이션을 실행합니다. 이 애플리케이션은 최대 시간대에 수십만 명의 사용자에게 서비스를 제공합니다. 이 회사는 수백만 건의 금융 거래에 대한 세부 정보를 여러 다른 내부 애플리케이션과 공유할 수 있는 확장 가능하고 거의 실시간에 가까운 솔루션이 필요합니다. 또한 트랜잭션은 저지연 검색을 위해 문서 데이터베이스에 저장되기 전에 민감한 데이터를 제거하기 위해 처리되어야 합니다.

솔루션 아키텍트는 이러한 요구 사항을 충족하기 위해 무엇을 권장해야 합니까?

A. 거래 데이터를 Amazon DynamoDB에 저장합니다. DynamoDB에 규칙을 설정하여 쓰기 시 모든 거래에서 민감한 데이터를 제거합니다. DynamoDB Streams를 사용하여 거래 데이터를 다른 애플리케이션과 공유합니다.
B. 거래 데이터를 Amazon Kinesis Data Firehose로 스트리밍하여 Amazon DynamoDB 및 Amazon S3에 데이터를 저장합니다. Kinesis Data Firehose와 AWS Lambda 통합을 사용하여 민감한 데이터를 제거합니다. 다른 애플리케이션은 Amazon S3에 저장된 데이터를 사용할 수 있습니다.
C. 거래 데이터를 Amazon Kinesis Data Streams로 스트리밍합니다. AWS Lambda 통합을 사용하여 모든 거래에서 민감한 데이터를 제거한 다음 거래 데이터를 Amazon DynamoDB에 저장합니다. 다른 애플리케이션은 Kinesis 데이터 스트림에서 거래 데이터를 사용할 수 있습니다.
D. 일괄 처리된 거래 데이터를 Amazon S3에 파일로 저장합니다. AWS Lambda를 사용하여 모든 파일을 처리하고 민감한 데이터를 제거한 후 Amazon S3에 있는 파일을 업데이트합니다. 그런 다음 Lambda 함수는 데이터를 Amazon DynamoDB에 저장합니다. 다른 애플리케이션은 Amazon S3에 저장된 거래 파일을 사용할 수 있습니다.

3. 한 회사는 Amazon EC2 인스턴스에서 실행되는 RESTful 웹 서비스 애플리케이션을 사용하여 수천 개의 원격 장치에서 데이터를 수집합니다. EC2 인스턴스는 원시 데이터를 수신하고, 원시 데이터를 변환하고, 모든 데이터를 Amazon S3 버킷에 저장합니다. 원격 장치의 수는 곧 수백만 개로 늘어날 것입니다. 이 회사는 운영 오버헤드를 최소화하는 확장성이 뛰어난 솔루션이 필요합니다.

솔루션 아키텍트는 이러한 요구 사항을 충족하기 위해 어떤 단계 조합을 취해야 합니까? (두 가지를 선택하세요.)

A. AWS Glue를 사용하여 Amazon S3의 원시 데이터를 처리합니다.
B. Amazon Route 53을 사용하여 다른 EC2 인스턴스로 트래픽을 라우팅합니다.
C. 점점 늘어나는 수신 데이터 양을 수용하기 위해 EC2 인스턴스를 더 추가합니다.
D. 원시 데이터를 Amazon Simple Queue Service(Amazon SQS)로 보냅니다. EC2 인스턴스를 사용하여 데이터를 처리합니다.
E. Amazon API Gateway를 사용하여 원시 데이터를 Amazon Kinesis 데이터 스트림으로 전송합니다. Amazon Kinesis Data Firehose를 구성하여 데이터 스트림을 소스로 사용하여 데이터를 Amazon S3로 전달합니다.

4. 한 회사에 TCP 및 UDP 멀티플레이어 게임 기능이 있는 온라인 게임 애플리케이션이 있습니다. 이 회사는 Amazon Route 53을 사용하여 애플리케이션 트래픽을 여러 AWS 지역의 여러 네트워크 로드 밸런서(NLB)로 연결합니다. 이 회사는 사용자 증가에 대비하여 온라인 게임의 애플리케이션 성능을 개선하고 지연 시간을 줄여야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. NLB 앞에 Amazon CloudFront 배포를 추가합니다. Cache-Control max-age 매개변수를 늘립니다.
B. NLB를 애플리케이션 로드 밸런서(ALB)로 교체합니다. Route 53을 구성하여 대기 시간 기반 라우팅을 사용합니다.
C. NLB 앞에 AWS Global Accelerator를 추가합니다. 올바른 리스너 포트를 사용하도록 Global Accelerator 엔드포인트를 구성합니다.
D. NLB 뒤에 Amazon API Gateway 엔드포인트를 추가합니다. API 캐싱을 활성화합니다. 다른 단계에 대한 메서드 캐싱을 재정의합니다.

5. 한 회사가 대량의 데이터를 저장하는 새로운 애플리케이션을 만들고 있습니다. 데이터는 매시간 분석되고 여러 가용성 영역에 배포된 여러 Amazon EC2 Linux 인스턴스에 의해 수정됩니다. 필요한 저장 공간의 양은 향후 6개월 동안 계속 증가할 것입니다.
솔루션 아키텍트는 이러한 요구 사항을 충족하기 위해 어떤 저장 솔루션을 권장해야 합니까?
A. Amazon S3 Glacier에 데이터를 저장합니다. S3 Glacier 볼트 정책을 업데이트하여 애플리케이션 인스턴스에 대한 액세스를 허용합니다.
B. Amazon Elastic Block Store(Amazon EBS) 볼륨에 데이터를 저장합니다. 애플리케이션 인스턴스에 EBS 볼륨을 마운트합니다.
C. Amazon Elastic File System(Amazon EFS) 파일 시스템에 데이터를 저장합니다. 애플리케이션 인스턴스에 파일 시스템을 마운트합니다.
D. 애플리케이션 인스턴스 간에 공유되는 Amazon Elastic Block Store(Amazon EBS) 프로비저닝된 IOPS 볼륨에 데이터를 저장합니다.